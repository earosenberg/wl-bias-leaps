{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a number of galaxies ($\\sim 500$ for testing, $\\gtrsim 50,000$ for good results) with intrinsic ellipticities taken from a uniform distribution of ellipticity ($\\epsilon$), distortion (e), or axis ratio (q), as given by an option. Also draw the phase uniformly from 0-pi (note that the orientation angle $\\phi$ is 0-$\\pi$ but in this space you need to cover the whole 0-$2\\pi$). Galaxy size is constant, gaussian profile.\n",
    "\n",
    "For each galaxy:\n",
    "    Apply an array of shears. Ex: g=\\[0+0i, 0.04+0i, -0.04+0i, 0+0.04i, 0-0.04i\\], but variable.\n",
    "    Apply Gaussian PSF and Gaussian noise. The same noise realisation for each shear value for a given galaxy, but different for each galaxy. \n",
    "    Rotate intrinsic shape by $n_{rot}$ times, where $n_{rot}$ is a variable. This gets treated as a separate galaxy with its own noise realisation.\n",
    "    \n",
    "Now we average: $\\hat g = \\langle \\epsilon \\rangle |_g$, converting from distortion to shear as appropriate. Only average galaxies with the same applied shear.\n",
    "Then we plot $\\hat g_1$ vs $g_1$, the observed shear vs real shear, and similarly for $g_2$. Remember to plot errors. Ideally there should be a straight line relation $(1+m_1)g_1 + c_1$ and similar. Fit with scipy curvefit to get parameters. Finally, repeat for different SNR, and plot SNR vs $m$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is not complete or fully tested. It is an R&D notebook from which I am borrowing code for other applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import galsim\n",
    "from scipy.optimize import curve_fit\n",
    "import time\n",
    "import cProfile\n",
    "import cPickle\n",
    "import emcee\n",
    "\n",
    "from galsim.gsparams import GSParams\n",
    "from galsim.hsm import HSMParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "shape_distribution = ['ellipticity','distortion','axis_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulation options\n",
    "distribution_key = 1 #choose shape_distribution from above\n",
    "matchRotNans = True #All rotated images of a galaxy are nan if one of them is nan, if True\n",
    "nrot = 2 #Number of images per galaxy ie 1 is no rotations, 2 is a 0 and 90 degree rot, etc\n",
    "ngal = 1000 #Number of galaxies to simulate\n",
    "shearList = [(0,0),(0.04,0),(-0.04,0),(0,0.04),(0,-0.04)] #list of shears to apply\n",
    "g1shear = [shear[0] for shear in shearList]\n",
    "g2shear = [shear[1] for shear in shearList]\n",
    "\n",
    "gsparams = galsim.GSParams(maximum_fft_size=12288)\n",
    "hsmp = galsim.hsm.HSMParams(max_mom2_iter=800) #double the default value\n",
    "\n",
    "#Parameters of the galaxy flux distribution\n",
    "m_min, m_max = 19, 25 #min, max magnitudes\n",
    "m0 = 25\n",
    "#Starting parameters for walkers; other MCMC parameters can be adjusted below\n",
    "init_add, init_mult = int(np.mean((m_min, m_max))), (m_max - m_min)/4.\n",
    "\n",
    "#Parameters of the galaxy ellipticity function\n",
    "epsilon0 = 0.35\n",
    "distortion_cutoff = 0.9\n",
    "shape_parameter_type = shape_distribution[distribution_key]\n",
    "\n",
    "#Other parameters of the galaxy population\n",
    "disk_n = 0.5  #n for Sersic profile; 1/2 for Gaussian\n",
    "disk_re = 0.8 #half-light radius, as\n",
    "\n",
    "#Parameters of the PSF\n",
    "psf_sigma = 0.5 #as\n",
    "pixel_scale = 0.3 #as/px\n",
    "\n",
    "#Parameters of the noise\n",
    "#snrArr = np.linspace(100,200,6) #array of desired SNRs for the Gaussian noise\n",
    "snrArr = np.array([0]) #Placeholder\n",
    "noise_sigma = 0.01 #Gives SNR ~300 for m = 20, m0=25\n",
    "\n",
    "#Gaussian PSF\n",
    "psf = galsim.Gaussian(flux=1.,sigma=psf_sigma)\n",
    "image_psf=psf.drawImage(scale=pixel_scale)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For magnitude distribution, use\n",
    "\n",
    "log_10 (N) = -8.85 + 0.71*m - 0.008*m*m for m from 19 to 28. You can use the zero point (m_0) as 25. Adjust the noise level so m=20 corresponds to SNR ~ 300.\n",
    "\n",
    "For ellipticity (\\epsilon) type, use Eq. 4 of http://arxiv.org/abs/1502.01883"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_hist_power_law(x,norm):\n",
    "      return norm* 10**(-8.85177133 +  0.716305260*x -0.00832345561*x*x)\n",
    "\n",
    "from scipy import interpolate\n",
    "## fnc is any callable functions defined\n",
    "def draw_samples_specified_distribution(nsamples, fnc, z,*args):\n",
    "    #zmin=1e-5\n",
    "    #zmax=20\n",
    "    #z = numpy.linspace(zmin,zmax) # Example indep variable\n",
    "    fofz = fnc(z,*args)\n",
    "    cdf_fofz = fofz.cumsum() # Next few steps to calculate CDF\n",
    "    cdf_fofz -= cdf_fofz[0] # w/appropriate normalization\n",
    "    cdf_fofz /= cdf_fofz[-1]\n",
    "    max_val = np.where(cdf_fofz==1)[0].min()+1 #Nothing in CDF above 1\n",
    "    cdf_fofz = cdf_fofz[:max_val] # cut off the trailing ones\n",
    "    z = z[:max_val]\n",
    "    model = interpolate.InterpolatedUnivariateSpline(cdf_fofz,z,k=4)\n",
    "    np.random.seed(seed=10)\n",
    "    samples = model(np.random.random(nsamples)) # Draw samples\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnitude(F,m0):\n",
    "    #Convert from flux to magnitude\n",
    "    return -2.5*np.log10(F)+m0\n",
    "def flux(m,m0):\n",
    "    #Convert from magnitude to flux\n",
    "    return 10**((m-m0)/(-2.5))\n",
    "\n",
    "magArr = np.linspace(m_min,m_max,10000)\n",
    "mags = draw_samples_specified_distribution(ngal, mag_hist_power_law, magArr, 1)\n",
    "fluxes = flux(mags, m0)\n",
    "#Plot histogram\n",
    "a=plt.hist(mags, 30, color=\"k\", histtype=\"step\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortion = np.random.rayleigh(epsilon0, size=ngal)\n",
    "#Place cut on distortion as they do in Hoekstra et al 2015\n",
    "while np.any(distortion>distortion_cutoff):\n",
    "    high_dist = np.where(distortion>distortion_cutoff)  \n",
    "    distortion[high_dist] = np.random.rayleigh(epsilon0, size=len(high_dist))\n",
    "shape_magnitude = distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate random numbers for intrinsic galaxy shapes\n",
    "#shape_params = np.random.random((ngal,2))\n",
    "phase = np.random.random(ngal)\n",
    "shape_params = np.stack((shape_magnitude, phase)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make catalog\n",
    "#Galaxy ID, Flux/magnitude, size, sersic n, intrinsic ellipticity\n",
    "\n",
    "galId = range(ngal)\n",
    "flux = fluxes\n",
    "size = [disk_re]*ngal\n",
    "sersic = [disk_n]*ngal\n",
    "shape1 = list(shape_params[:,0])\n",
    "shape2 = list(shape_params[:,1] * np.pi)\n",
    "\n",
    "input_cat = np.stack((galId,flux,size,sersic,shape1,shape2)).transpose()\n",
    "header = 'galId flux size sersic shape1 shape2 nrot'\n",
    "np.savetxt('../shear_bias_outputs/input_cat.txt',input_cat,delimiter=' ',header=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intrinsic_shear(galaxy,shape_parameter_type,mag,ph):\n",
    "    if shape_parameter_type == 'ellipticity':\n",
    "        newGal = galaxy.shear(g=mag, beta=ph*galsim.radians)\n",
    "    elif shape_parameter_type == 'distortion':\n",
    "        newGal = galaxy.shear(e=mag, beta=ph*galsim.radians)\n",
    "    elif shape_parameter_type == 'axis_ratio':\n",
    "        newGal = galaxy.shear(q=mag, beta=ph*galsim.radians)\n",
    "    else:\n",
    "        raise ValueError, 'shape_parameter_type \"%s\" not recognized. Use one of the allowed keywords.' %shape_parameter_type\n",
    "    return newGal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load catalog\n",
    "cat = np.loadtxt('../shear_bias_outputs/input_cat.txt', skiprows=1)\n",
    "flux = cat[:,1]\n",
    "disk_reArr, disk_nArr = cat[:,2],cat[:,3]\n",
    "magArr,phArr = cat[:,4],cat[:,5]\n",
    "\n",
    "#Generate galaxies\n",
    "galaxies = [galsim.Sersic(disk_n,half_light_radius=disk_re,gsparams=gsparams) for (disk_re,disk_n) in zip(disk_reArr,disk_nArr)]\n",
    "galaxies = [gal.withFlux(gal_flux) for gal,gal_flux in zip(galaxies,flux)]\n",
    "galaxies = [intrinsic_shear(galaxy,shape_parameter_type,mag,ph) for galaxy,mag,ph in zip(galaxies,magArr,phArr)]\n",
    "\n",
    "#Generate rotated galaxies, add to galaxy list\n",
    "rotation_angle = [180./(nrot)*i for i in range(1,nrot)]\n",
    "rot_gals = [gal.rotate(angle*galsim.degrees) for angle in rotation_angle for gal in galaxies]\n",
    "galaxies += rot_gals\n",
    "\n",
    "# rotation_angle = [180./(nrot)*i for i in range(0,nrot)]\n",
    "# rot_gals = [[gal.rotate(angle*galsim.degrees) for angle in rotation_angle] for gal in galaxies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shear galaxies\n",
    "shearedGals = np.array([[gal.shear(g1=shear[0],g2=shear[1]) for gal in galaxies] for shear in shearList])\n",
    "#shearedGals (numShears, numGals)\n",
    "\n",
    "# shearedGals = np.array([[[gal.shear(g1=shear[0],g2=shear[1]) for gal in subgal] for subgal in rot_gals] for shear in shearList])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measure shapes\n",
    "#replace disk_re with catalog\n",
    "def measureShape(noise_im, image_psf):\n",
    "        results = galsim.hsm.EstimateShear(noise_im,image_psf,strict=False,\\\n",
    "                                           guess_sig_gal=disk_re/pixel_scale, guess_sig_PSF=psf_sigma/pixel_scale,\\\n",
    "                                           shear_est='REGAUSS', hsmparams = hsmp)\n",
    "        if results.correction_status==0:\n",
    "            return [results.corrected_e1, results.corrected_e2, results.corrected_shape_err,0]\n",
    "        #if shape estimation unsuccessful\n",
    "        else:\n",
    "            if 'NaN' in results.error_message:\n",
    "                em = -11\n",
    "            elif 'adaptive' in results.error_message:\n",
    "                em = -9\n",
    "            elif 'min/max' in results.error_message:\n",
    "                em = -7\n",
    "            else:\n",
    "                print results.error_message\n",
    "                em = -999\n",
    "\n",
    "            return [np.nan, np.nan, np.nan,em]\n",
    "    \n",
    "def addGaussianNoiseSNR(im,clean_im,snr):\n",
    "    noise = galsim.GaussianNoise(sigma=1)\n",
    "    im.addNoiseSNR(noise, snr, preserve_flux=True)\n",
    "    noise_im = im - clean_im\n",
    "    return noise_im\n",
    "\n",
    "def addGaussianNoise(im,clean_im,sigma):\n",
    "    noise = galsim.GaussianNoise(sigma=sigma)\n",
    "    im.addNoise(noise)\n",
    "    noise_im = im - clean_im\n",
    "    return noise_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startC,startT = time.clock(), time.time()\n",
    "save_ims = False #CAREFUL making this True; it will expend all of your memory very rapidly\n",
    "obs = []\n",
    "shearedGalT = shearedGals.transpose()\n",
    "#Iterate over rows of the same galaxy w/ different shears\n",
    "noisyGals=[]\n",
    "for galRowNum,galRow in enumerate(shearedGalT):\n",
    "    gal_ims = []\n",
    "    for i,gal in enumerate(galRow):\n",
    "        #Convolve w/ PSF and draw image\n",
    "        final = galsim.Convolve([gal, psf])\n",
    "        if i==0:\n",
    "            image = final.drawImage(scale=pixel_scale)\n",
    "        else:\n",
    "            image_shape = gal_ims[0].array.shape\n",
    "            im_final = galsim.ImageF(*image_shape)\n",
    "            image = final.drawImage(image=im_final, scale=pixel_scale)\n",
    "        gal_ims.append(image)\n",
    "\n",
    "    obs_snr = []\n",
    "    #Loop through SNRs\n",
    "    for snr in snrArr:\n",
    "        #Add noise\n",
    "        first = gal_ims[0].copy()\n",
    "        #noise_im = addGaussianNoiseSNR(first, gal_ims[0], snr)\n",
    "        noise_im = addGaussianNoise(first, gal_ims[0], noise_sigma)\n",
    "        noisyImRow = [im + noise_im for im in gal_ims]\n",
    "        if save_ims:\n",
    "            noisyGals.append(noisyImRow)\n",
    "        #Measure shape\n",
    "        obsRow = [measureShape(noisyIm, image_psf) for noisyIm in noisyImRow]\n",
    "        obs_snr.append(obsRow)\n",
    "\n",
    "    obs.append(obs_snr)\n",
    "\n",
    "obs = np.array(obs)\n",
    "obs=np.stack([obs[ngal*i:ngal*(i+1)] for i in range(nrot)]) #Put rotated versions in new axis\n",
    "#nrot, ngal, snr, shear, meas\n",
    "obs = obs.transpose(2,1,0,3,4) #Get desired shape\n",
    "\n",
    "error_message = obs[:,:,:,:,-1]\n",
    "shape_err = obs[:,:,:,:,-2]\n",
    "obs = obs[:,:,:,:,:-2] #remove shape error from obs\n",
    "print obs.shape\n",
    "#Save file\n",
    "# outfile2 = open('../shear_bias_outputs/obs.pkl','wb')\n",
    "# cPickle.dump(obs,outfile2)\n",
    "# outfile2.close()\n",
    "\n",
    "print 'clock time: %10.1f \\n cpu time: %10.1f' % (time.clock()-startC,time.time()-startT)\n",
    "print 'len(shearedGals) = ', shearedGals.size\n",
    "\n",
    "#cProfile.run('a()',sort=1)\n",
    "\n",
    "#obs shape:\n",
    "#(#SNRs, ngal, nrot, #shears, 2)\n",
    "#Axis 0: SNR\n",
    "#Axis 1: Galaxy #\n",
    "#Axis 2: Rotated versions\n",
    "#Axis 3: Shear\n",
    "#Axis 4: shape measurement: [e1corr, e2corr] or [nan, nan] in case of failure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nanErr = [error_message==-11]\n",
    "numIterErr = [error_message==-9]\n",
    "minmaxErr = [error_message==-7]\n",
    "otherErr = [error_message==-999]\n",
    "print 'NaN Err: ',np.sum(nanErr), '\\nnumIter Err: ', np.sum(numIterErr), '\\nMin/Max Err: ', \\\n",
    "np.sum(minmaxErr), '\\nOther Err: ', np.sum(otherErr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchRotatedNans(obs):\n",
    "    '''If any of the rotations of a single galaxy are nan, make all rotations nan'''\n",
    "    tempObs = obs.transpose(0,1,3,2,4) #(SNR, ngal, shear, nrot, (e1, e2))\n",
    "    for i in range(tempObs.shape[0]):\n",
    "        for j in range(tempObs.shape[1]):\n",
    "            for k in range(tempObs.shape[2]):\n",
    "                if np.any(np.isnan(tempObs[i,j,k])):\n",
    "                    for m in range(tempObs.shape[3]):\n",
    "                        tempObs[i,j,k,m] = [np.nan] * tempObs[i,j,k,m].size\n",
    "    obs = tempObs.transpose(0,1,3,2,4) \n",
    "    return obs\n",
    "\n",
    "if matchRotNans:\n",
    "    obs = matchRotatedNans(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print obs.shape\n",
    "print fluxes.shape\n",
    "failed_fluxes = np.isnan(obs)\n",
    "np.sum(failed_fluxes) / float(obs.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nanav(array, weights, axis=None):\n",
    "    '''Take weighted average of an array, ignoring nan values\n",
    "       array: ndarray object. weights: array of same size, giving weights.\n",
    "       axis: int giving axis to average along\n",
    "       returns: array averaged along given axis, ignoring nans'''\n",
    "    ma = np.ma.MaskedArray(array, mask=np.isnan(array))\n",
    "    av = np.ma.average(ma, weights=weights, axis=axis)\n",
    "    if isinstance(av, np.ndarray):\n",
    "        if np.any(av.mask):\n",
    "            raise ValueError, 'Average should not contain np.nan'\n",
    "        else:\n",
    "            return av.data\n",
    "    else:\n",
    "        return av\n",
    "\n",
    "def findMeanShear(obs,weights):\n",
    "    '''obs: array of measured distortions, shape (SNR, Galaxy#, nrot, Shear, (e1,e2))\n",
    "       weights: array of weights\n",
    "       Returns estimate of mean shear, shape (SNR, Shear, (g1,g2))'''\n",
    "    distortionMean = nanav(obs,weights, axis=(1,2))\n",
    "    distSqMean = np.nanmean(obs[:,:,:,:,0]**2 + obs[:,:,:,:,1]**2)/2.\n",
    "    mean = distortionMean / (2 * (1-distSqMean)) #Formula for approximate shear\n",
    "    return mean\n",
    "\n",
    "#Keep rotated pairs together when bootstrapping\n",
    "\n",
    "def bootstrapShear(obs,weights,nBootstrap):    \n",
    "    '''obs,weights: as above. nBootstrap: int, number of times to resample\n",
    "       Returns array of shape (nBootstrap,SNR,shear,(g1,g2)) giving samples of mean shear'''\n",
    "    size=obs.shape[1]\n",
    "    shearSamples = []\n",
    "    for i in xrange(nBootstrap):\n",
    "        np.random.seed(seed=i) #seed=None to use a random seed\n",
    "        randNums = np.random.random(size)\n",
    "        ncounts, bin_edges = np.histogram(randNums, bins=size, range=(0,1))\n",
    "        ncounts = ncounts.reshape(1,len(ncounts),1,1,1)\n",
    "        for i in [0,2,3,4]:\n",
    "            ncounts = ncounts.repeat(weights.shape[i],axis=i)\n",
    "\n",
    "        newWeights = weights * ncounts\n",
    "        shearSample = findMeanShear(obs, newWeights)\n",
    "        shearSamples.append(shearSample)\n",
    "    shearSamples = np.stack(shearSamples)\n",
    "    return shearSamples\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mates = np.reshape(weights, weights.shape+(1,))\n",
    "mates = np.repeat(mates, obs.shape[-1], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define weights\n",
    "shape_noise2 = np.var(magArr) #shape noise is variance of input ellipticities\n",
    "\n",
    "weights = 1/(shape_noise2 + shape_err**2)\n",
    "weights[np.isnan(weights)] = 0 #Set weight to zero if nan\n",
    "weights = np.reshape(weights, weights.shape + (1,))\n",
    "weights = np.repeat(weights, obs.shape[-1], axis=-1)\n",
    "\n",
    "#weights = np.ones_like(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startC,startT = time.clock(), time.time()\n",
    "\n",
    "#Find weighted g1 and g2 from e1, e2\n",
    "meanShear= findMeanShear(obs,weights)\n",
    "#Use bootstrap method to resample and derive an error on the shear values\n",
    "size = obs.shape[1]\n",
    "nBootstrap = int(size*np.log(size)**2)\n",
    "shearSamples = bootstrapShear(obs,weights,nBootstrap)\n",
    "errShear = np.std(shearSamples,axis=0) / np.sqrt(nBootstrap)\n",
    "meanShearBootstrap = np.mean(shearSamples,axis=0)\n",
    "print 'clock time: %10.1f \\n cpu time: %10.1f' % (time.clock()-startC,time.time()-startT)\n",
    "\n",
    "#Combine mean and err into a single array\n",
    "res = np.stack((meanShear,errShear)).transpose(3,1,2,0)\n",
    "\n",
    "#res Shape: (measurements, SNRs, shears, (mean, err))\n",
    "#plt.hist(shearSamples[:,0,0,0],bins=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin(x,m,b):\n",
    "    return m*x+b\n",
    "\n",
    "def fitline(shear,data,err):\n",
    "    fitparam, fiterr = curve_fit(lin,shear,data,p0=[1,0],sigma=err)\n",
    "    return fitparam\n",
    "\n",
    "def getFitParameters(shearList,fullRes):\n",
    "    '''\n",
    "    fullRes is an array of shape (measurements, SNRs, shears, (mean, err))\n",
    "    shearList is a list of 2-tupes of true shear\n",
    "    '''\n",
    "    #Iterate over measurements\n",
    "    g1shear = [shear[0] for shear in shearList]\n",
    "    g2shear = [shear[1] for shear in shearList]\n",
    "    shear=(g1shear,g2shear)\n",
    "    fullParamArr=[]\n",
    "    for i,res in enumerate(fullRes[:2]):\n",
    "        fitParamArr = []\n",
    "        #Iterate over SNRs\n",
    "        for subRes in res:\n",
    "            fitparams = fitline(shear[i],subRes[:,0],subRes[:,1]) \n",
    "            fitParamArr.append(fitparams)\n",
    "        fullParamArr.append(fitParamArr)\n",
    "    return np.array(fullParamArr) #Shape (2 (g1, g2), #SNRs, 2 (slope, intercept of line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fits nBootstrap * nShear * 2 (g1,g2) lines\n",
    "#~1.7s / 10k fits\n",
    "def bootstrapM(shearSamples,shearList):\n",
    "    '''shearSamples as above. shearList is a list of 2-tuples of true shear\n",
    "       Return array of shape (nBootstrap, 2 (g1,g2), SNRs)'''\n",
    "    mSamples=[]\n",
    "    sigma = np.ones_like(shearSamples)[0] #Use 1 for all errors (same as no error)\n",
    "    for sample in shearSamples:\n",
    "        sampleRes = np.stack([sample,sigma]).transpose(3,1,2,0)\n",
    "        gparams= getFitParameters(shearList,sampleRes)       \n",
    "        mSamples.append(gparams[:,:,0])\n",
    "    mSamples=np.stack(mSamples)\n",
    "    return mSamples\n",
    "\n",
    "sh=shearSamples.shape\n",
    "estTime = sh[0]*sh[1]*sh[2] * (1.7/10000.)\n",
    "print 'Estimated time: %10.1f seconds' % estTime\n",
    "startC,startT = time.clock(), time.time()\n",
    "mSamples = bootstrapM(shearSamples,shearList) #shape: numSamples, 2 (g1,g2), SNRs\n",
    "mStd = np.std(mSamples,axis=0) / np.sqrt(nBootstrap)\n",
    "mMeanBootstrap = np.mean(mSamples,axis=0)\n",
    "#mStd shape: ((g1,g2), SNRs)\n",
    "\n",
    "mMean = getFitParameters(shearList,res)[:,:,0]\n",
    "print 'clock time: %10.1f \\n cpu time: %10.1f' % (time.clock()-startC,time.time()-startT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print mSamples.shape\n",
    "for i in range(len(snrArr)):\n",
    "    plt.hist(mSamples[:,0,i],bins=20,histtype='step',label=str(snrArr[i]))\n",
    "plt.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get mean from bootstrap, compare to true mean\n",
    "#keep option to kill all rotations if one of them fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(snrArr,mMean[0]-1,yerr=mStd[0],fmt='o',c='b',capsize=4,label='Mean m1',alpha=0.7,marker='o')\n",
    "plt.scatter(snrArr,mMeanBootstrap[0]-1,c='r',label='Bootstrap Mean m1',marker='o')\n",
    "plt.xlabel('SNR')\n",
    "plt.ylabel('m')\n",
    "\n",
    "plt.errorbar(snrArr,mMean[1]-1,yerr=mStd[1],fmt='o',c='b',capsize=4,label='Mean m2',alpha=0.7,marker='*')\n",
    "plt.scatter(snrArr,mMeanBootstrap[1]-1,c='r',label='Bootstrap Mean m2',marker='*')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shearComp(shearList,i):\n",
    "    return [shear[i] for shear in shearList]\n",
    "\n",
    "def plotFit(shear,res,snr_index,measurement,fitparams):\n",
    "    subRes = res[measurement,snr_index]\n",
    "    plt.errorbar(shear, subRes[:,0]-shear,yerr=subRes[:,1],fmt='.',capsize=4,c='b',label='Mean')\n",
    "    xx=np.linspace(min(shear),max(shear),len(shear)*100)\n",
    "    plt.plot(xx,lin(xx,*fitparams[snr_index])-xx,'k')\n",
    "    plt.title('SNR: '+str(snrArr[snr_index]))\n",
    "    plt.xlabel('True g'+str(measurement+1))\n",
    "    plt.ylabel('Measured g' + str(measurement+1) + ' - true g'+str(measurement+1))\n",
    "\n",
    "def fitAndPlot(shearList,res,snr_index,measurement):\n",
    "    fitparams = getFitParameters(shearList,res)[measurement]\n",
    "    plotFit(shearComp(shearList,measurement),res,snr_index,measurement,fitparams)\n",
    "    \n",
    "#y axis: measured shear - true shear. x-axis true shear\n",
    "#Say for which SNR is this plot\n",
    "#specify SNR through function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y axis: measured shear - true shear. x-axis true shear\n",
    "#Say for which SNR is this plot\n",
    "#specify SNR through function\n",
    "snr_index, measurement = 0,0\n",
    "fitAndPlot(shearList,res,snr_index,measurement)\n",
    "shear = (g1shear,g2shear)[measurement]\n",
    "plt.scatter(shear,meanShearBootstrap[snr_index,:,measurement]-shear,c='r',label='Bootstrap Mean')\n",
    "plt.legend()\n",
    "print snrArr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use more realistic distributions of flux and ellipticity. Can still calculate separately for each SNR but combine to get m for all snrs\n",
    "use the 3 g2=0 points for m1 calc, vice versa for m2 calc\n",
    "to look for cross term and x\n",
    "\n",
    "weights = 1/(shape noise^2 + shape_err^2) \n",
    "shape_err is from estimate shear\n",
    "shape noise: variance of ellipticities: for now input ellipticities\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
